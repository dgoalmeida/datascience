{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6db0e9e3",
   "metadata": {},
   "source": [
    "## Spark Streaming Twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc176134",
   "metadata": {},
   "outputs": [],
   "source": [
    "# se não tiver instalado, instale os pacotes a baixo\n",
    "#!pip install requests_oauthlib\n",
    "#!pip install twython\n",
    "#!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc00ff2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# modulos que serão usados\n",
    "from pyspark.streaming import StreamingContext\n",
    "from pyspark import SparkContext\n",
    "from requests_oauthlib import OAuth2Session\n",
    "from operator import add\n",
    "import requests_oauthlib\n",
    "from time import gmtime, strftime\n",
    "import requests\n",
    "import time\n",
    "import string\n",
    "import ast\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd2b80d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importando pacotes NLTK\n",
    "import nltk\n",
    "from nltk.classify import NaiveBayesClassifier\n",
    "from nltk.sentiment import SentimentAnalyzer\n",
    "from nltk.corpus import subjectivity\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.sentiment.util import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08227ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a63bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# variaval que define o intervalo que vamos obter os twits \n",
    "INTERNALO_BATCH = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d5b7cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# criando o streamingContext\n",
    "ssc = StreamingContext(sc, INTERNALO_BATCH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aca4de94",
   "metadata": {},
   "source": [
    "### Treinando classificador de análise de sentimento\n",
    "\n",
    "Uma parte essencial da criação de um algoritmo de análise de sentimento (ou qualquer outro algoritmo de mineração de dados) é ter um conjunto de dados abrangente \"Corpus\" para o aprendizado, bem como um conjunto de dado de teste para garantir que a precisão do seu algoritmo atenda aos padrões que você espera. Isso também permitirá que voê ajuste o seu algoritmo a fim de deduzir melhores (ou mais precisas) caracteristicas da linguagem natural que voce poderia extrair do texto, e que vão contribuir para análise de sentimento em vez de usar uma abordagem genérica. tomaremos como base o dataset de treino fornecido pela universidade de Michigam para competições do kaggle\n",
    "\n",
    "label\n",
    "### 1 para sentimento positivo\n",
    "### 0 para sentimento negativo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8555332",
   "metadata": {},
   "outputs": [],
   "source": [
    "arquivo = sc.textFile('2-Arquivos-Cap10/dataset_analise_sentimento.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd0cb79",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(arquivo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ab5c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# removendo o cabeçalho\n",
    "header = arquivo.take(1)[0]\n",
    "dataset = arquivo.filter(lambda x: x != header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9780b4b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0607ea5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# função para separar colunas em cada linha, cria uma tupla e remove pontuação\n",
    "def get_row(linha):\n",
    "    row = linha.split(',') # separo por virgula\n",
    "    sentimento = row[1] # pego a linha de indice 1 que é a posição do sentimento \n",
    "    tweet = row[3].strip() # dividindo cada uma das linhas com o strip\n",
    "    translator = str.maketrans({key: None for key in string.punctuation}) # removendo a pontuação com o string.punctuation\n",
    "    tweet = tweet.translate(translator)\n",
    "    tweet = tweet.split(\" \") # separa por espaço\n",
    "    tweet_lower = [] # adicionando palavras em uma nova lista porem em lower case\n",
    "    for word in tweet:\n",
    "        tweet_lower.append(word.lower())\n",
    "    return (tweet_lower,sentimento)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a251dda0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# aplica a função a cada linha do dataset\n",
    "dataset_treino = dataset.map(lambda x: get_row(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a3a7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cria um objeto SentimentAnalyzer\n",
    "sentiment_analyzer = SentimentAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66dc1889",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9aab521",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image(url='2-Arquivos-Cap10/ntlkdata.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d27230",
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtem a lista de stopwords em ingles\n",
    "stopword_all = []\n",
    "for word in stopwords.words('english'):\n",
    "    stopword_all.append(word)\n",
    "    stopword_all.append(word+'_NEG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c3ea48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtem 10.000 tweets do dataset de treino \n",
    "dataset_treino_amostra = dataset_treino.take(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d58cf97e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_treino_amostra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae010824",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words_neg = sentiment_analyzer.all_words([mark_negation(doc) for doc in dataset_treino_amostra])\n",
    "all_words_neg_nostops = [x for x in all_words_neg if x not in stopword_all]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "355ad6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cria um unigram e extrai as features\n",
    "unigram_feats = sentiment_analyzer.unigram_word_feats(all_words_neg_nostops, top_n=200)\n",
    "sentiment_analyzer.add_feat_extractor(extract_unigram_feats, unigrams = unigram_feats)\n",
    "training_set = sentiment_analyzer.apply_features(dataset_treino_amostra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1392f767",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b92a0b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b45c47be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# treinando modelo\n",
    "trainer = NaiveBayesClassifier.train\n",
    "classifier = sentiment_analyzer.train(trainer, training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ca66f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sentence1 = [(['this','program','is','bad'],'')]\n",
    "test_sentence2 = [(['thogh','day', 'at','work','today'],'')]\n",
    "test_sentence3 = [(['good','wonderful','amazing','awsomw'],'')]\n",
    "t1 = sentiment_analyzer.apply_features(test_sentence1)\n",
    "t2 = sentiment_analyzer.apply_features(test_sentence2)\n",
    "t3 = sentiment_analyzer.apply_features(test_sentence3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f9d590ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "consumer_key = \"XXX\"\n",
    "consumer_secret = \"XXX\"\n",
    "access_token = \"XXX\"\n",
    "access_secret = \"XXX\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "58a4ba85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-twitter in /Users/dgoalmeida/Library/r-miniconda/lib/python3.8/site-packages (3.5)\n",
      "Requirement already satisfied: requests-oauthlib in /Users/dgoalmeida/Library/r-miniconda/lib/python3.8/site-packages (from python-twitter) (1.3.0)\n",
      "Requirement already satisfied: requests in /Users/dgoalmeida/Library/r-miniconda/lib/python3.8/site-packages (from python-twitter) (2.25.1)\n",
      "Requirement already satisfied: future in /Users/dgoalmeida/Library/r-miniconda/lib/python3.8/site-packages (from python-twitter) (0.18.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/dgoalmeida/Library/r-miniconda/lib/python3.8/site-packages (from requests->python-twitter) (2021.10.8)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /Users/dgoalmeida/Library/r-miniconda/lib/python3.8/site-packages (from requests->python-twitter) (4.0.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/dgoalmeida/Library/r-miniconda/lib/python3.8/site-packages (from requests->python-twitter) (1.26.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /Users/dgoalmeida/Library/r-miniconda/lib/python3.8/site-packages (from requests->python-twitter) (2.10)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /Users/dgoalmeida/Library/r-miniconda/lib/python3.8/site-packages (from requests-oauthlib->python-twitter) (3.1.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install python-twitter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d440d6df",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = twitter.Api(\n",
    "    consumer_key = consumer_key, \n",
    "    consumer_secret = consumer_secret, \n",
    "    access_token_key = access_token, \n",
    "    access_token_secret = access_secret, \n",
    "    tweet_mode = 'extended')\n",
    "\n",
    "t."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb54127",
   "metadata": {},
   "outputs": [],
   "source": [
    "# criando objeto de autenticação do twitter\n",
    "auth = requests_oauthlib.OAuth1(consumer_key, consumer_secret, access_token, access_secret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b4e240e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# configurando stream\n",
    "rdd = ssc.sparkContext.parallelize([0])\n",
    "stream = ssc.queueStream([],default=rdd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a254b603",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f16a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# numero de tweets por update\n",
    "NUM_TWEETS = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd99e313",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "            \n",
    "# Essa função conecta ao Twitter e retorna um número específico de Tweets (NUM_TWEETS)\n",
    "def tfunc(t, rdd):\n",
    "  return rdd.flatMap(lambda x: stream_twitter_data())\n",
    "\n",
    "def stream_twitter_data():\n",
    "  response = requests.get(filter_url, auth = auth, stream = True)\n",
    "  print(filter_url, response)\n",
    "  count = 0\n",
    "  for line in response.iter_lines():\n",
    "    try:\n",
    "      if count > NUM_TWEETS:\n",
    "        break\n",
    "      post = json.loads(line.decode('utf-8'))\n",
    "      contents = [post['text']]\n",
    "      count += 1\n",
    "      yield str(contents)\n",
    "    except:\n",
    "      result = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "567e8488",
   "metadata": {},
   "outputs": [],
   "source": [
    "stream = stream.transform(tfunc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26fc92c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "coord_stream = stream.map(lambda x: ast.literal_eval(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e55ba857",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifica_tweet(tweet):\n",
    "    sentence = [(tweet), '']\n",
    "    test_set = sentiment_analyzer.apply_features(sentence)\n",
    "    print(tweet, classifier.classify(test_set[0][0]))\n",
    "    return (tweet, classifier.classify(test_set[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b1ae152",
   "metadata": {},
   "outputs": [],
   "source": [
    "# retorna o txt odo twitter\n",
    "def get_tweet_text(rdd):\n",
    "    for line in rdd:\n",
    "        tweet = line.strip()\n",
    "        print(tweet)\n",
    "        translator = str.maketrans({key: None for key in string.punctuation}) # removendo a pontuação com o string.punctuation\n",
    "        tweet = tweet.translate(translator)\n",
    "        tweet = tweet.split(' ') # separa por espaço\n",
    "        tweet_lower = [] # adicionando palavras em uma nova lista porem em lower case\n",
    "        for word in tweet:\n",
    "            tweet_lower.append(word.lower())\n",
    "        return (classifica_tweet(tweet_lower))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef1147a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "509b4ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_rdd(rdd):\n",
    "    global resultados\n",
    "    pairs = rdd.map(lambda x: (get_tweet_text(x)[1],1))\n",
    "    counts = pairs.reduceByKey(add)\n",
    "    output = []\n",
    "    for count in counts.collect():\n",
    "        output.append(count)\n",
    "    result = (time.strftime(\"%I:%M:%S\"), output)\n",
    "    resultados.append(result)\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da75916",
   "metadata": {},
   "outputs": [],
   "source": [
    "coord_stream.foreachRDD(lambda t, rdd: output_rdd(rdd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f84dfb9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ssc.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3112f491",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = True\n",
    "while count:\n",
    "    if(len(resultados) > 5):\n",
    "        count = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51008c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd_save = '2-Arquivos-Cap10/r'+time.strftime('%I%M%S')\n",
    "resultado_rdd = sc.parallelize(resultado)\n",
    "resultado_rdd.saveAsTextFilee(rdd_save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82255b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "resultado_rdd.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43dbb259",
   "metadata": {},
   "outputs": [],
   "source": [
    "ssc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74de409e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
